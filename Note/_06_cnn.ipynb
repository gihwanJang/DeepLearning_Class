{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55ebc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from datetime import datetime\n",
    "import os\n",
    "import wandb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ce278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "\n",
    "class DeltaTemplate(Template):\n",
    "    delimiter = \"%\"\n",
    "\n",
    "    def strfdelta(tdelta, fmt):\n",
    "        d = {\"D\": tdelta.days}\n",
    "        d[\"H\"], rem = divmod(tdelta.seconds, 3600)\n",
    "        d[\"M\"], d[\"S\"] = divmod(rem, 60)\n",
    "        t = DeltaTemplate(fmt)\n",
    "        return t.substitute(**d)\n",
    "\n",
    "def strfdelta(td, fmt):\n",
    "\n",
    "    # Get the timedelta’s sign and absolute number of seconds.\n",
    "    sign = \"-\" if td.days < 0 else \"+\"\n",
    "    secs = abs(td).total_seconds()\n",
    "\n",
    "    # Break the seconds into more readable quantities.\n",
    "    days, rem = divmod(secs, 86400)  # Seconds per day: 24 * 60 * 60\n",
    "    hours, rem = divmod(rem, 3600)  # Seconds per hour: 60 * 60\n",
    "    mins, secs = divmod(rem, 60)\n",
    "\n",
    "    # Format (as per above answers) and return the result string.\n",
    "    t = DeltaTemplate(fmt)\n",
    "    return t.substitute(\n",
    "            s=sign,\n",
    "            D=\"{:d}\".format(int(days)),\n",
    "            H=\"{:02d}\".format(int(hours)),\n",
    "            M=\"{:02d}\".format(int(mins)),\n",
    "            S=\"{:02d}\".format(int(secs)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20924bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=10, delta=0.0001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.delta = delta\n",
    "\n",
    "        self.val_loss_min = None\n",
    "        self.file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "        )\n",
    "        self.latest_file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "        )\n",
    "\n",
    "    def check_and_save(self, new_validation_loss, model):\n",
    "        early_stop = False\n",
    "\n",
    "        if self.val_loss_min is None:\n",
    "            self.val_loss_min = new_validation_loss\n",
    "            message = f'Early stopping is stated!'\n",
    "        elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "            message = f'V_loss decreased ({self.val_loss_min:6.3f} --> {new_validation_loss:6.3f}). Saving model...'\n",
    "            self.save_checkpoint(new_validation_loss, model)\n",
    "            self.val_loss_min = new_validation_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "            if self.counter >= self.patience:\n",
    "                early_stop = True\n",
    "                message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "\n",
    "        return message, early_stop\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        torch.save(model.state_dict(), self.file_path)\n",
    "        torch.save(model.state_dict(), self.latest_file_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2e06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTrainer:\n",
    "    def __init__(\n",
    "        self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "        run_time_str, wandb, device, checkpoint_file_path\n",
    "    ):\n",
    "        self.project_name = project_name\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.validation_data_loader = validation_data_loader\n",
    "        self.transforms = transforms\n",
    "        self.run_time_str = run_time_str\n",
    "        self.wandb = wandb\n",
    "        self.device = device\n",
    "        self.checkpoint_file_path = checkpoint_file_path\n",
    "\n",
    "        # Use a built-in loss function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def do_train(self):\n",
    "        self.model.train()  # Explained at 'Diverse Techniques' section\n",
    "\n",
    "        loss_train = 0.0\n",
    "        num_corrects_train = 0\n",
    "        num_trained_samples = 0\n",
    "        num_trains = 0\n",
    "\n",
    "        for train_batch in self.train_data_loader:\n",
    "            input_train, target_train = train_batch\n",
    "            input_train = input_train.to(device=self.device)\n",
    "            target_train = target_train.to(device=self.device)\n",
    "\n",
    "            input_train = self.transforms(input_train)\n",
    "\n",
    "            output_train = self.model(input_train)\n",
    "            loss = self.loss_fn(output_train, target_train)\n",
    "            loss_train += loss.item()\n",
    "\n",
    "            predicted_train = torch.argmax(output_train, dim=1)\n",
    "            num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "\n",
    "            num_trained_samples += len(input_train)\n",
    "            num_trains += 1\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        train_loss = loss_train / num_trains\n",
    "        train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    def do_validation(self):\n",
    "        self.model.eval()   # Explained at 'Diverse Techniques' section\n",
    "\n",
    "        loss_validation = 0.0\n",
    "        num_corrects_validation = 0\n",
    "        num_validated_samples = 0\n",
    "        num_validations = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for validation_batch in self.validation_data_loader:\n",
    "                input_validation, target_validation = validation_batch\n",
    "                input_validation = input_validation.to(device=self.device)\n",
    "                target_validation = target_validation.to(device=self.device)\n",
    "\n",
    "                input_validation = self.transforms(input_validation)\n",
    "\n",
    "                output_validation = self.model(input_validation)\n",
    "                loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "\n",
    "                predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "                num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "\n",
    "                num_validated_samples += len(input_validation)\n",
    "                num_validations += 1\n",
    "\n",
    "        validation_loss = loss_validation / num_validations\n",
    "        validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "\n",
    "        return validation_loss, validation_accuracy\n",
    "\n",
    "    def train_loop(self):\n",
    "        early_stopping = EarlyStopping(\n",
    "        patience=self.wandb.config.early_stop_patience,\n",
    "        project_name=self.project_name,\n",
    "        checkpoint_file_path=self.checkpoint_file_path,\n",
    "        run_time_str=self.run_time_str\n",
    "        )\n",
    "        n_epochs = self.wandb.config.epochs\n",
    "        training_start_time = datetime.now()\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            train_loss, train_accuracy = self.do_train()\n",
    "\n",
    "            if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "                validation_loss, validation_accuracy = self.do_validation()\n",
    "\n",
    "                elapsed_time = datetime.now() - training_start_time\n",
    "                epoch_per_second = epoch / elapsed_time.seconds\n",
    "\n",
    "                message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "\n",
    "                print(\n",
    "                    f\"[Epoch {epoch:>3}] \"\n",
    "                    f\"T_loss: {train_loss:6.4f}, \"\n",
    "                    f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "                    f\"V_loss: {validation_loss:6.4f}, \"\n",
    "                    f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "                    f\"{message} | \"\n",
    "                    f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "                    f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "                )\n",
    "\n",
    "                self.wandb.log({\n",
    "                    \"Epoch\": epoch,\n",
    "                    \"Training loss\": train_loss,\n",
    "                    \"Training accuracy (%)\": train_accuracy,\n",
    "                    \"Validation loss\": validation_loss,\n",
    "                    \"Validation accuracy (%)\": validation_accuracy,\n",
    "                    \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "                })\n",
    "\n",
    "                if early_stop:\n",
    "                    break\n",
    "\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c83097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTester:\n",
    "    def __init__(self, project_name, model, test_data_loader, transforms, checkpoint_file_path):\n",
    "        self.project_name = project_name\n",
    "        self.model = model\n",
    "        self.test_data_loader = test_data_loader\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.latest_file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "        )\n",
    "\n",
    "        print(\"MODEL FILE: {0}\".format(self.latest_file_path))\n",
    "\n",
    "        self.model.load_state_dict(torch.load(self.latest_file_path, map_location=torch.device('cpu')))\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()    # Explained at 'Diverse Techniques' section\n",
    "\n",
    "        num_corrects_test = 0\n",
    "        num_tested_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for test_batch in self.test_data_loader:\n",
    "                input_test, target_test = test_batch\n",
    "\n",
    "                input_test = self.transforms(input_test)\n",
    "\n",
    "                output_test = self.model(input_test)\n",
    "\n",
    "                predicted_test = torch.argmax(output_test, dim=1)\n",
    "                num_corrects_test += torch.sum(torch.eq(predicted_test, target_test))\n",
    "\n",
    "                num_tested_samples += len(input_test)\n",
    "\n",
    "            test_accuracy = 100.0 * num_corrects_test / num_tested_samples\n",
    "\n",
    "        print(f\"TEST RESULTS: {test_accuracy:6.3f}%\")\n",
    "\n",
    "    def test_single(self, input_test):\n",
    "        self.model.eval()    # Explained at 'Diverse Techniques' section\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_test = self.transforms(input_test)\n",
    "\n",
    "            output_test = self.model(input_test)\n",
    "            predicted_test = torch.argmax(output_test, dim=1)\n",
    "\n",
    "        return predicted_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af11097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "CHECKPOINT_FILE_PATH = \"./Mnist_Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cb15fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(flatten=False):\n",
    "    data_path = \"../Data/h_h_mnist\"\n",
    "\n",
    "    mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "    mnist_train, mnist_validation = random_split(mnist_train, [55_000, 5_000])\n",
    "\n",
    "    print(\"Num Train Samples: \", len(mnist_train))\n",
    "    print(\"Num Validation Samples: \", len(mnist_validation))\n",
    "\n",
    "    #num_data_loading_workers = os.cpu_count() or 1\n",
    "    num_data_loading_workers = 1\n",
    "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=mnist_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.1307, std=0.3081),\n",
    "    )\n",
    "\n",
    "    if flatten:\n",
    "        mnist_transforms.append(nn.Flatten())\n",
    "\n",
    "    return train_data_loader, validation_data_loader, mnist_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20f431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c499a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self, in_channels, n_output):\n",
    "            super().__init__()\n",
    "\n",
    "            self.model = nn.Sequential(\n",
    "                # B x 1 x 28 x 28 --> B x 6 x (28 - 5 + 1) x (28 - 5 + 1) = B x 6 x 24 x 24\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "                # B x 6 x 24 x 24 --> B x 6 x 12 x 12\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                # B x 6 x 12 x 12 --> B x 16 x (12 - 5 + 1) x (12 - 5 + 1) = B x 16 x 8 x 8\n",
    "                nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "                # B x 16 x 8 x 8 --> B x 16 x 4 x 4\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, n_output),\n",
    "              )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.model(x)\n",
    "            return x\n",
    "\n",
    "    # 1 * 28 * 28\n",
    "    my_model = MyModel(in_channels=1, n_output=10)\n",
    "\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bc07478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args_wandb, args_epochs, args_batch_size, args_validation_intervals, args_learning_rate, args_early_stop_patience):\n",
    "    run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    config = {\n",
    "        'epochs': args_epochs,\n",
    "        'batch_size': args_batch_size,\n",
    "        'validation_intervals': args_validation_intervals,\n",
    "        'learning_rate': args_learning_rate,\n",
    "        'early_stop_patience': args_early_stop_patience\n",
    "    }\n",
    "\n",
    "    project_name = \"cnn_mnist\"\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args_wandb else \"disabled\",\n",
    "        project=project_name,\n",
    "        notes=\"mnist experiment with cnn\",\n",
    "        tags=[\"cnn\", \"mnist\"],\n",
    "        name=run_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(wandb.config)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on device {device}.\")\n",
    "\n",
    "    train_data_loader, validation_data_loader, mnist_transforms = get_mnist_data(flatten=False)\n",
    "    model = get_cnn_model()\n",
    "    model.to(device)\n",
    "    wandb.watch(model)\n",
    "\n",
    "    from torchinfo import summary\n",
    "    summary(model=model, input_size=(1, 1, 28, 28))\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "    classification_trainer = ClassificationTrainer(\n",
    "        project_name, model, optimizer, train_data_loader, validation_data_loader, mnist_transforms,\n",
    "        run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
    "    )\n",
    "    classification_trainer.train_loop()\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8312f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zey5qgd7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9859fae1c3c24389a15636cd596d86ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▄█</td></tr><tr><td>Training accuracy (%)</td><td>▁██</td></tr><tr><td>Training loss</td><td>█▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁▇█</td></tr><tr><td>Validation accuracy (%)</td><td>▁██</td></tr><tr><td>Validation loss</td><td>█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>20</td></tr><tr><td>Training accuracy (%)</td><td>97.44364</td></tr><tr><td>Training loss</td><td>0.08463</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.07692</td></tr><tr><td>Validation accuracy (%)</td><td>97.46</td></tr><tr><td>Validation loss</td><td>0.08921</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2023-10-25_12-27-29</strong> at: <a href='https://wandb.ai/gihwanjang/cnn_mnist/runs/zey5qgd7' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_mnist/runs/zey5qgd7</a><br/> View job at <a href='https://wandb.ai/gihwanjang/cnn_mnist/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwOTY4NzA0Mg==/version_details/v3' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_mnist/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEwOTY4NzA0Mg==/version_details/v3</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231025_122729-zey5qgd7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zey5qgd7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e441680b5f964628b48bb7c04a9eb56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167615744569856, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jang-gihwan/Desktop/DeepLearing/AI_Learning/Note/wandb/run-20231025_123217-ciyved0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gihwanjang/cnn_mnist/runs/ciyved0u' target=\"_blank\">2023-10-25_12-32-17</a></strong> to <a href='https://wandb.ai/gihwanjang/cnn_mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gihwanjang/cnn_mnist' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_mnist</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gihwanjang/cnn_mnist/runs/ciyved0u' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_mnist/runs/ciyved0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 200, 'batch_size': 32, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 10}\n",
      "Training on device cpu.\n",
      "Num Train Samples:  55000\n",
      "Num Validation Samples:  5000\n",
      "Number of Data Loading Workers: 1\n",
      "[Epoch   1] T_loss: 2.2501, T_accuracy: 21.8509 | V_loss: 2.0942, V_accuracy: 52.7200 | Early stopping is stated! | T_time: 00:00:14, T_speed: 0.071\n",
      "[Epoch  10] T_loss: 0.1458, T_accuracy: 95.8382 | V_loss: 0.1414, V_accuracy: 96.0200 | V_loss decreased ( 2.094 -->  0.141). Saving model... | T_time: 00:02:07, T_speed: 0.079\n",
      "[Epoch  20] T_loss: 0.0876, T_accuracy: 97.4164 | V_loss: 0.0923, V_accuracy: 97.5000 | V_loss decreased ( 0.141 -->  0.092). Saving model... | T_time: 00:04:13, T_speed: 0.079\n",
      "[Epoch  30] T_loss: 0.0653, T_accuracy: 98.0236 | V_loss: 0.0762, V_accuracy: 97.8600 | V_loss decreased ( 0.092 -->  0.076). Saving model... | T_time: 00:06:20, T_speed: 0.079\n",
      "[Epoch  40] T_loss: 0.0523, T_accuracy: 98.4291 | V_loss: 0.0645, V_accuracy: 98.1600 | V_loss decreased ( 0.076 -->  0.064). Saving model... | T_time: 00:08:26, T_speed: 0.079\n",
      "[Epoch  50] T_loss: 0.0441, T_accuracy: 98.6327 | V_loss: 0.0605, V_accuracy: 98.4400 | V_loss decreased ( 0.064 -->  0.061). Saving model... | T_time: 00:10:33, T_speed: 0.079\n",
      "[Epoch  60] T_loss: 0.0377, T_accuracy: 98.8636 | V_loss: 0.0567, V_accuracy: 98.4000 | V_loss decreased ( 0.061 -->  0.057). Saving model... | T_time: 00:12:39, T_speed: 0.079\n",
      "[Epoch  70] T_loss: 0.0327, T_accuracy: 99.0236 | V_loss: 0.0542, V_accuracy: 98.4800 | V_loss decreased ( 0.057 -->  0.054). Saving model... | T_time: 00:14:45, T_speed: 0.079\n",
      "[Epoch  80] T_loss: 0.0286, T_accuracy: 99.1218 | V_loss: 0.0543, V_accuracy: 98.5400 | Early stopping counter: 1 out of 10 | T_time: 00:16:51, T_speed: 0.079\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m args_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m      9\u001b[0m args_early_stop_patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_wandb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_validation_intervals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_early_stop_patience\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 40\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args_wandb, args_epochs, args_batch_size, args_validation_intervals, args_learning_rate, args_early_stop_patience)\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mwandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m     36\u001b[0m classification_trainer \u001b[38;5;241m=\u001b[39m ClassificationTrainer(\n\u001b[1;32m     37\u001b[0m     project_name, model, optimizer, train_data_loader, validation_data_loader, mnist_transforms,\n\u001b[1;32m     38\u001b[0m     run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mclassification_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m, in \u001b[0;36mClassificationTrainer.train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m training_start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 95\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mvalidation_intervals \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     98\u001b[0m         validation_loss, validation_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_validation()\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mClassificationTrainer.do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m num_trained_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     26\u001b[0m num_trains \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data_loader:\n\u001b[1;32m     29\u001b[0m     input_train, target_train \u001b[38;5;241m=\u001b[39m train_batch\n\u001b[1;32m     30\u001b[0m     input_train \u001b[38;5;241m=\u001b[39m input_train\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:256\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:423\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 423\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    927\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 930\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #parser = get_parser()\n",
    "    #args = parser.parse_args()\n",
    "    args_wandb = True\n",
    "    args_epochs = 200\n",
    "    args_batch_size = 32\n",
    "    args_validation_intervals = 10\n",
    "    args_learning_rate = 0.001\n",
    "    args_early_stop_patience = 10\n",
    "    main(args_wandb, args_epochs, args_batch_size, args_validation_intervals, args_learning_rate, args_early_stop_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00490e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5456577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5ec4352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_test_data(flatten=False):\n",
    "    data_path = \"../Data/h_mnist\"\n",
    "\n",
    "    mnist_test_images = datasets.MNIST(data_path, train=False, download=True)\n",
    "\n",
    "    mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "    test_data_loader = DataLoader(dataset=mnist_test, batch_size=len(mnist_test))\n",
    "\n",
    "    mnist_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.1307, std=0.3081),\n",
    "    )\n",
    "\n",
    "    if flatten:\n",
    "        mnist_transforms.append(\n",
    "        nn.Flatten()\n",
    "    )\n",
    "\n",
    "    return mnist_test_images, test_data_loader, mnist_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28a2cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mnist_test_images, test_data_loader, mnist_transforms = get_mnist_test_data(flatten=False)\n",
    "\n",
    "    test_model = get_cnn_model()\n",
    "    classification_tester = ClassificationTester(\n",
    "        \"cnn_mnist\", test_model, test_data_loader, mnist_transforms, CHECKPOINT_FILE_PATH\n",
    "    )\n",
    "    classification_tester.test()\n",
    "\n",
    "    print()\n",
    "\n",
    "    img, label = mnist_test_images[0]\n",
    "    print(\"     LABEL:\", label)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    # torch.tensor(np.array(mnist_test_images[0][0])).unsqueeze(dim=0).unsqueeze(dim=0).shape: (1, 1, 28, 28)\n",
    "    output = classification_tester.test_single(\n",
    "        torch.tensor(np.array(mnist_test_images[0][0])).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "    )\n",
    "    print(\"PREDICTION:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46809a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FILE: ./Mnist_Output/cnn_mnist_checkpoint_latest.pt\n",
      "TEST RESULTS: 98.920%\n",
      "\n",
      "     LABEL: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION: 7\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84defd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba432a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import wandb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7860d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_data(flatten=False):\n",
    "    data_path = \"../Data/i_cifar10\"\n",
    "\n",
    "    print(\"DATA PATH: {0}\".format(data_path))\n",
    "\n",
    "    cifar10_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "    cifar10_train, cifar10_validation = random_split(cifar10_train, [45_000, 5_000])\n",
    "\n",
    "    print(\"Num Train Samples: \", len(cifar10_train))\n",
    "    print(\"Num Validation Samples: \", len(cifar10_validation))\n",
    "\n",
    "    num_data_loading_workers = 1\n",
    "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        dataset=cifar10_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    validation_data_loader = DataLoader(\n",
    "        dataset=cifar10_validation, batch_size=wandb.config.batch_size,\n",
    "        pin_memory=True, num_workers=num_data_loading_workers\n",
    "    )\n",
    "\n",
    "    cifar10_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=(0.4915, 0.4823, 0.4468), std=(0.2470, 0.2435, 0.2616)),\n",
    "    )\n",
    "\n",
    "    if flatten:\n",
    "        cifar10_transforms.append(nn.Flatten())\n",
    "\n",
    "    return train_data_loader, validation_data_loader, cifar10_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74930114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "  class MyModel(nn.Module):\n",
    "    def __init__(self, in_channels, n_output):\n",
    "      super().__init__()\n",
    "\n",
    "      self.model = nn.Sequential(\n",
    "        # B x 3 x 32 x 32 --> B x 6 x (32 - 5 + 1) x (32 - 5 + 1) = B x 6 x 28 x 28\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=6, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        # B x 6 x 28 x 28 --> B x 6 x 14 x 14\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        # B x 6 x 14 x 14 --> B x 16 x (14 - 5 + 1) x (14 - 5 + 1) = B x 16 x 10 x 10\n",
    "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1)),\n",
    "        # B x 16 x 10 x 10 --> B x 16 x 5 x 5\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(400, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, n_output),\n",
    "      )\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.model(x)\n",
    "      # print(x.shape, \"!!!\")\n",
    "      return x\n",
    "\n",
    "  # 3 * 32 * 32\n",
    "  my_model = MyModel(in_channels=3, n_output=10)\n",
    "\n",
    "  return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fee8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args_wandb, args_epochs, args_batch_size, args_validation_intervals, args_learning_rate, args_early_stop_patience):\n",
    "  run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  config = {\n",
    "    'epochs': args_epochs,\n",
    "    'batch_size': args_batch_size,\n",
    "    'validation_intervals': args_validation_intervals,\n",
    "    'learning_rate': args_learning_rate,\n",
    "    'early_stop_patience': args_early_stop_patience\n",
    "  }\n",
    "\n",
    "  project_name = \"cnn_cifar10\"\n",
    "  wandb.init(\n",
    "    mode=\"online\" if args_wandb else \"disabled\",\n",
    "    project=project_name,\n",
    "    notes=\"cifar10 experiment with cnn\",\n",
    "    tags=[\"cnn\", \"cifar10\"],\n",
    "    name=run_time_str,\n",
    "    config=config\n",
    "  )\n",
    "  print(wandb.config)\n",
    "\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f\"Training on device {device}.\")\n",
    "\n",
    "  train_data_loader, validation_data_loader, cifar10_transforms = get_cifar10_data(flatten=False)\n",
    "  model = get_cnn_model()\n",
    "  model.to(device)\n",
    "  wandb.watch(model)\n",
    "\n",
    "  from torchinfo import summary\n",
    "  summary(model=model, input_size=(1, 3, 32, 32))\n",
    "\n",
    "  optimizer = optim.SGD(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "  classification_trainer = ClassificationTrainer(\n",
    "    project_name, model, optimizer, train_data_loader, validation_data_loader, cifar10_transforms,\n",
    "    run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
    "  )\n",
    "  classification_trainer.train_loop()\n",
    "\n",
    "  wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39033c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgihwan319\u001b[0m (\u001b[33mgihwanjang\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6025ecc9790a4fdf9f285de583ff9eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168994900071994, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jang-gihwan/Desktop/DeepLearing/AI_Learning/Note/wandb/run-20231101_111353-7ypur1dp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gihwanjang/cnn_cifar10/runs/7ypur1dp' target=\"_blank\">2023-11-01_11-13-52</a></strong> to <a href='https://wandb.ai/gihwanjang/cnn_cifar10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gihwanjang/cnn_cifar10' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_cifar10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gihwanjang/cnn_cifar10/runs/7ypur1dp' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_cifar10/runs/7ypur1dp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 200, 'batch_size': 32, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 10}\n",
      "Training on device cpu.\n",
      "DATA PATH: ../Data/i_cifar10\n",
      "Files already downloaded and verified\n",
      "Num Train Samples:  45000\n",
      "Num Validation Samples:  5000\n",
      "Number of Data Loading Workers: 1\n",
      "[Epoch   1] T_loss: 2.2883, T_accuracy: 13.1622 | V_loss: 2.2595, V_accuracy: 17.9000 | Early stopping is stated! | T_time: 00:00:29, T_speed: 0.034\n",
      "[Epoch  10] T_loss: 1.5524, T_accuracy: 44.5933 | V_loss: 1.5475, V_accuracy: 44.1400 | V_loss decreased ( 2.260 -->  1.548). Saving model... | T_time: 00:03:41, T_speed: 0.045\n",
      "[Epoch  20] T_loss: 1.3417, T_accuracy: 52.1867 | V_loss: 1.3364, V_accuracy: 53.0800 | V_loss decreased ( 1.548 -->  1.336). Saving model... | T_time: 00:07:10, T_speed: 0.047\n",
      "[Epoch  30] T_loss: 1.2121, T_accuracy: 57.2044 | V_loss: 1.2122, V_accuracy: 57.3000 | V_loss decreased ( 1.336 -->  1.212). Saving model... | T_time: 00:10:39, T_speed: 0.047\n",
      "[Epoch  40] T_loss: 1.1221, T_accuracy: 60.6733 | V_loss: 1.1884, V_accuracy: 58.0000 | V_loss decreased ( 1.212 -->  1.188). Saving model... | T_time: 00:14:10, T_speed: 0.047\n",
      "[Epoch  50] T_loss: 1.0536, T_accuracy: 63.2444 | V_loss: 1.1111, V_accuracy: 61.1000 | V_loss decreased ( 1.188 -->  1.111). Saving model... | T_time: 00:17:41, T_speed: 0.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  60] T_loss: 0.9955, T_accuracy: 65.3711 | V_loss: 1.1003, V_accuracy: 61.7000 | V_loss decreased ( 1.111 -->  1.100). Saving model... | T_time: 00:21:10, T_speed: 0.047\n",
      "[Epoch  70] T_loss: 0.9457, T_accuracy: 67.1556 | V_loss: 1.0486, V_accuracy: 64.0800 | V_loss decreased ( 1.100 -->  1.049). Saving model... | T_time: 00:25:04, T_speed: 0.047\n",
      "[Epoch  80] T_loss: 0.9000, T_accuracy: 68.7422 | V_loss: 1.0390, V_accuracy: 64.8200 | V_loss decreased ( 1.049 -->  1.039). Saving model... | T_time: 00:29:04, T_speed: 0.046\n",
      "[Epoch  90] T_loss: 0.8585, T_accuracy: 70.1756 | V_loss: 1.0438, V_accuracy: 64.9400 | Early stopping counter: 1 out of 10 | T_time: 00:32:46, T_speed: 0.046\n",
      "[Epoch 100] T_loss: 0.8185, T_accuracy: 71.6356 | V_loss: 1.0636, V_accuracy: 64.1800 | Early stopping counter: 2 out of 10 | T_time: 00:36:25, T_speed: 0.046\n",
      "[Epoch 110] T_loss: 0.7798, T_accuracy: 72.9822 | V_loss: 1.1000, V_accuracy: 64.0400 | Early stopping counter: 3 out of 10 | T_time: 00:40:06, T_speed: 0.046\n",
      "[Epoch 120] T_loss: 0.7438, T_accuracy: 74.4200 | V_loss: 1.0615, V_accuracy: 64.8600 | Early stopping counter: 4 out of 10 | T_time: 00:43:46, T_speed: 0.046\n",
      "[Epoch 130] T_loss: 0.7089, T_accuracy: 75.4889 | V_loss: 1.0805, V_accuracy: 64.5600 | Early stopping counter: 5 out of 10 | T_time: 00:47:25, T_speed: 0.046\n",
      "[Epoch 140] T_loss: 0.6735, T_accuracy: 76.8111 | V_loss: 1.1181, V_accuracy: 64.0200 | Early stopping counter: 6 out of 10 | T_time: 00:51:06, T_speed: 0.046\n",
      "[Epoch 150] T_loss: 0.6421, T_accuracy: 77.8800 | V_loss: 1.1514, V_accuracy: 63.7400 | Early stopping counter: 7 out of 10 | T_time: 00:54:51, T_speed: 0.046\n",
      "[Epoch 160] T_loss: 0.6131, T_accuracy: 79.0533 | V_loss: 1.1583, V_accuracy: 64.0400 | Early stopping counter: 8 out of 10 | T_time: 00:58:40, T_speed: 0.045\n",
      "[Epoch 170] T_loss: 0.5834, T_accuracy: 79.8467 | V_loss: 1.1781, V_accuracy: 64.1200 | Early stopping counter: 9 out of 10 | T_time: 01:02:27, T_speed: 0.045\n",
      "[Epoch 180] T_loss: 0.5529, T_accuracy: 81.0200 | V_loss: 1.1859, V_accuracy: 64.4200 | Early stopping counter: 10 out of 10 *** TRAIN EARLY STOPPED! *** | T_time: 01:06:16, T_speed: 0.045\n",
      "Final training time: 01:06:16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>Training accuracy (%)</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>Training loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁▇██████▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Validation accuracy (%)</td><td>▁▅▆▇▇▇█████████████</td></tr><tr><td>Validation loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>180</td></tr><tr><td>Training accuracy (%)</td><td>81.02</td></tr><tr><td>Training loss</td><td>0.55292</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.04527</td></tr><tr><td>Validation accuracy (%)</td><td>64.42</td></tr><tr><td>Validation loss</td><td>1.18589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2023-11-01_11-13-52</strong> at: <a href='https://wandb.ai/gihwanjang/cnn_cifar10/runs/7ypur1dp' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_cifar10/runs/7ypur1dp</a><br/> View job at <a href='https://wandb.ai/gihwanjang/cnn_cifar10/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMTcyOTg4Mg==/version_details/v0' target=\"_blank\">https://wandb.ai/gihwanjang/cnn_cifar10/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMTcyOTg4Mg==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231101_111353-7ypur1dp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #parser = get_parser()\n",
    "    #args = parser.parse_args()\n",
    "    args_wandb = True\n",
    "    args_epochs = 200\n",
    "    args_batch_size = 32\n",
    "    args_validation_intervals = 10\n",
    "    args_learning_rate = 0.001\n",
    "    args_early_stop_patience = 10\n",
    "    main(args_wandb, args_epochs, args_batch_size, args_validation_intervals, args_learning_rate, args_early_stop_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8360a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b86596b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "import os\n",
    "import wandb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6cae2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10_test_data(flatten=False):\n",
    "    data_path = \"../Data/i_cifar10\"\n",
    "\n",
    "    cifar10_test_images = datasets.CIFAR10(data_path, train=False, download=True)\n",
    "\n",
    "    cifar10_test = datasets.CIFAR10(data_path, train=False, download=False, transform=transforms.ToTensor())\n",
    "    test_data_loader = DataLoader(dataset=cifar10_test, batch_size=len(cifar10_test))\n",
    "\n",
    "    cifar10_transforms = nn.Sequential(\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize(mean=0.1307, std=0.3081),\n",
    "    )\n",
    "\n",
    "    if flatten:\n",
    "        cifar10_transforms.append(nn.Flatten())\n",
    "\n",
    "    return cifar10_test_images, test_data_loader, cifar10_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22209658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cifar10_test_images, test_data_loader, cifar10_transforms = get_cifar10_test_data(flatten=False)\n",
    "\n",
    "    test_model = get_cnn_model()\n",
    "    classification_tester = ClassificationTester(\n",
    "        \"cnn_cifar10\", test_model, test_data_loader, cifar10_transforms, CHECKPOINT_FILE_PATH\n",
    "    )\n",
    "    classification_tester.test()\n",
    "\n",
    "    print()\n",
    "\n",
    "    img, label = cifar10_test_images[0]\n",
    "    print(\"     LABEL:\", label)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    # torch.tensor(np.array(cifar10_test_images[0][0])).permute(2, 0, 1).unsqueeze(dim=0).shape: (1, 3, 32, 32)\n",
    "    output = classification_tester.test_single(\n",
    "        torch.tensor(np.array(cifar10_test_images[0][0])).permute(2, 0, 1).unsqueeze(dim=0)\n",
    "    )\n",
    "    print(\"PREDICTION:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f01a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "MODEL FILE: ./Mnist_Output/cnn_cifar10_checkpoint_latest.pt\n",
      "TEST RESULTS: 44.650%\n",
      "\n",
      "     LABEL: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION: 3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf33855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
