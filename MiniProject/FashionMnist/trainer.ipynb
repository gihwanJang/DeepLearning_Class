{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb7c48e-4f82-446c-bc11-d5fc10544dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c538c2-37e6-4899-a26a-857318a01825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from utils import strfdelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bada22e-523e-4239-8ee2-857bccb16845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.0001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.delta = delta\n",
    "        \n",
    "        self.val_loss_min = None\n",
    "        self.file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
    "        )\n",
    "        self.latest_file_path = os.path.join(\n",
    "            checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
    "        )\n",
    "    \n",
    "    def check_and_save(self, new_validation_loss, model):\n",
    "        early_stop = False\n",
    "    \n",
    "        if self.val_loss_min is None:\n",
    "            self.val_loss_min = new_validation_loss\n",
    "            message = f'Early stopping is stated!'\n",
    "        elif new_validation_loss < self.val_loss_min - self.delta:\n",
    "            message = f'V_loss decreased ({self.val_loss_min:6.3f} --> {new_validation_loss:6.3f}). Saving model...'\n",
    "            self.save_checkpoint(new_validation_loss, model)\n",
    "            self.val_loss_min = new_validation_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
    "            if self.counter >= self.patience:\n",
    "                early_stop = True\n",
    "                message += \" *** TRAIN EARLY STOPPED! ***\"\n",
    "        \n",
    "        return message, early_stop\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), self.file_path)\n",
    "        torch.save(model.state_dict(), self.latest_file_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf3c887-c48d-42fa-8495-98902e9dd300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTrainer:\n",
    "    def __init__(\n",
    "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
    "    run_time_str, wandb, device, checkpoint_file_path\n",
    "    ):\n",
    "        self.project_name = project_name\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_data_loader = train_data_loader\n",
    "        self.validation_data_loader = validation_data_loader\n",
    "        self.transforms = transforms\n",
    "        self.run_time_str = run_time_str\n",
    "        self.wandb = wandb\n",
    "        self.device = device\n",
    "        self.checkpoint_file_path = checkpoint_file_path\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def do_train(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        loss_train = 0.0\n",
    "        num_corrects_train = 0\n",
    "        num_trained_samples = 0\n",
    "        num_trains = 0\n",
    "        \n",
    "        for train_batch in self.train_data_loader:\n",
    "            input_train, target_train = train_batch\n",
    "            input_train = input_train.to(device=self.device)\n",
    "            target_train = target_train.to(device=self.device)\n",
    "            \n",
    "            if self.transforms:\n",
    "                input_train = self.transforms(input_train)\n",
    "            \n",
    "            output_train = self.model(input_train)\n",
    "            \n",
    "            loss = self.loss_fn(output_train, target_train)\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "            predicted_train = torch.argmax(output_train, dim=1)\n",
    "            num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
    "            \n",
    "            num_trained_samples += len(input_train)\n",
    "            num_trains += 1\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        train_loss = loss_train / num_trains\n",
    "        train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
    "        \n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    def do_validation(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        loss_validation = 0.0\n",
    "        num_corrects_validation = 0\n",
    "        num_validated_samples = 0\n",
    "        num_validations = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for validation_batch in self.validation_data_loader:\n",
    "                input_validation, target_validation = validation_batch\n",
    "                input_validation = input_validation.to(device=self.device)\n",
    "                target_validation = target_validation.to(device=self.device)\n",
    "                \n",
    "                if self.transforms:\n",
    "                    input_validation = self.transforms(input_validation)\n",
    "                \n",
    "                output_validation = self.model(input_validation)\n",
    "                loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
    "                \n",
    "                predicted_validation = torch.argmax(output_validation, dim=1)\n",
    "                num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
    "                \n",
    "                num_validated_samples += len(input_validation)\n",
    "                num_validations += 1\n",
    "        \n",
    "        validation_loss = loss_validation / num_validations\n",
    "        validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
    "        \n",
    "        return validation_loss, validation_accuracy\n",
    "\n",
    "    def train_loop(self):\n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=self.wandb.config.early_stop_patience,\n",
    "            project_name=self.project_name,\n",
    "            checkpoint_file_path=self.checkpoint_file_path,\n",
    "            run_time_str=self.run_time_str\n",
    "        )\n",
    "        n_epochs = self.wandb.config.epochs\n",
    "        training_start_time = datetime.now()\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            train_loss, train_accuracy = self.do_train()\n",
    "\n",
    "            if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
    "                validation_loss, validation_accuracy = self.do_validation()\n",
    "    \n",
    "                elapsed_time = datetime.now() - training_start_time\n",
    "                epoch_per_second = 0 if elapsed_time.seconds == 0 else epoch / elapsed_time.seconds\n",
    "    \n",
    "                message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
    "    \n",
    "                print(\n",
    "                    f\"[Epoch {epoch:>3}] \"\n",
    "                    f\"T_loss: {train_loss:6.4f}, \"\n",
    "                    f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
    "                    f\"V_loss: {validation_loss:6.4f}, \"\n",
    "                    f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
    "                    f\"{message} | \"\n",
    "                    f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
    "                    f\"T_speed: {epoch_per_second:4.3f}\"\n",
    "                )\n",
    "    \n",
    "                self.wandb.log({\n",
    "                  \"Epoch\": epoch,\n",
    "                  \"Training loss\": train_loss,\n",
    "                  \"Training accuracy (%)\": train_accuracy,\n",
    "                  \"Validation loss\": validation_loss,\n",
    "                  \"Validation accuracy (%)\": validation_accuracy,\n",
    "                  \"Training speed (epochs/sec.)\": epoch_per_second,\n",
    "                })\n",
    "    \n",
    "                if early_stop:\n",
    "                  break\n",
    "\n",
    "        elapsed_time = datetime.now() - training_start_time\n",
    "        print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18deddce-33e6-497e-9e7f-289215b49749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
