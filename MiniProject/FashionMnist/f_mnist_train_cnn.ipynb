{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28486044-5347-4157-a293-209533843a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import os\n",
    "import wandb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e879160-86f4-46dc-90bc-611e66515dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BASE_PATH = \"./\"\n",
    "sys.path.append(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea7e454-2646-40fc-b164-b4a83cc6b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_FILE_PATH = \"./\"\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "  os.makedirs(os.path.join(CURRENT_FILE_PATH, \"checkpoints\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "116e0222-af65-4453-beb7-0574cfa23f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from fashion_mnist_data import get_fashion_mnist_data, get_fashion_mnist_test_data\n",
    "from trainer import ClassificationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d703ab-4f92-4df5-b14d-5b9a4b324dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_MNIST(nn.Module):\n",
    "    def __init__(self, in_channels, n_output):\n",
    "        super(CNN_MNIST, self).__init__()\n",
    "\n",
    "        # 첫 번째 Convolutional Layer: 32개의 3x3 커널, 패딩 1\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # Batch Normalization\n",
    "        # 두 번째 Convolutional Layer: 64개의 3x3 커널, 패딩 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  # Batch Normalization\n",
    "        # Max Pooling Layer: 2x2 커널, 스트라이드 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 첫 번째 Fully Connected Layer: 64 * 7 * 7 크기의 입력을 받아 128개의 뉴런 생성\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        # 두 번째 Fully Connected Layer: 128개의 뉴런에서 10개의 출력 뉴런 생성 (클래스 수)\n",
    "        self.fc2 = nn.Linear(128, n_output)\n",
    "        # Dropout Layer: 50%의 확률로 뉴런을 비활성화하여 과적합 방지\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 Convolutional Layer를 통과하고 활성화 함수 및 Batch Normalization을 적용\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # 두 번째 Convolutional Layer를 통과하고 활성화 함수 및 Batch Normalization을 적용\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        # 2D 이미지를 1D 벡터로 평탄화\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        # 첫 번째 Fully Connected Layer를 통과하고 활성화 함수를 적용\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Dropout을 적용하여 과적합 방지\n",
    "        x = self.dropout(x)\n",
    "        # 두 번째 Fully Connected Layer를 통과하여 최종 출력 생성\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06430404-cff3-43a9-82fb-a0dc032c8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    improved_cnn_mnist_model = CNN_MNIST(in_channels=1, n_output=10)\n",
    "    return improved_cnn_mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87033d8f-8153-4b45-a57b-63871faa9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    \n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'validation_intervals': args.validation_intervals,\n",
    "        'learning_rate': args.learning_rate,\n",
    "        'early_stop_patience': args.early_stop_patience\n",
    "    }\n",
    "    \n",
    "    project_name = \"fashion_mnist_cnn\"\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args.wandb else \"disabled\",\n",
    "        project=project_name,\n",
    "        notes=\"fashion mnist with cnn\",\n",
    "        name=run_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Training on device {device}.\")\n",
    "    \n",
    "    train_data_loader, validation_data_loader, mnist_transforms = get_fashion_mnist_data()\n",
    "    model = get_cnn_model()\n",
    "    model.to(device)\n",
    "    mnist_transforms.to(device)\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    from torchinfo import summary\n",
    "    summary(model=model, input_size=(1, 1, 28, 28))\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "    \n",
    "    classification_trainer = ClassificationTrainer(\n",
    "        project_name, model, optimizer, train_data_loader, validation_data_loader, mnist_transforms,\n",
    "        run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
    "    )\n",
    "    classification_trainer.train_loop()\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "748b8191-5467-4c7f-9383-4020e88609b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jang-gihwan/Desktop/DeepLearing/AI_Learning/MiniProject/FashionMnist/wandb/run-20231111_153533-36fzzi1n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gihwanjang/fashion_mnist_cnn/runs/36fzzi1n' target=\"_blank\">2023-11-11_15-35-33</a></strong> to <a href='https://wandb.ai/gihwanjang/fashion_mnist_cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gihwanjang/fashion_mnist_cnn' target=\"_blank\">https://wandb.ai/gihwanjang/fashion_mnist_cnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gihwanjang/fashion_mnist_cnn/runs/36fzzi1n' target=\"_blank\">https://wandb.ai/gihwanjang/fashion_mnist_cnn/runs/36fzzi1n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, batch_size=2048, epochs=10000, learning_rate=0.001, validation_intervals=10, early_stop_patience=10)\n",
      "{'epochs': 10000, 'batch_size': 2048, 'validation_intervals': 10, 'learning_rate': 0.001, 'early_stop_patience': 10}\n",
      "Training on device cpu.\n",
      "Num Train Samples:  55000\n",
      "Num Validation Samples:  5000\n",
      "Sample Shape:  torch.Size([1, 28, 28])\n",
      "Number of Data Loading Workers: 1\n",
      "torch.Size([1, 28, 28, 55000])\n",
      "mean : tensor([0.2859]), std : tensor([0.3529])\n",
      "[Epoch   1] T_loss: 0.9103, T_accuracy: 67.6436 | V_loss: 0.5256, V_accuracy: 82.7800 | Early stopping is stated! | T_time: 00:00:26, T_speed: 0.038\n",
      "[Epoch  10] T_loss: 0.2520, T_accuracy: 91.2036 | V_loss: 0.2362, V_accuracy: 91.1200 | V_loss decreased ( 0.526 -->  0.236). Saving model... | T_time: 00:04:13, T_speed: 0.040\n",
      "[Epoch  20] T_loss: 0.1755, T_accuracy: 93.6636 | V_loss: 0.2080, V_accuracy: 92.7800 | V_loss decreased ( 0.236 -->  0.208). Saving model... | T_time: 00:08:26, T_speed: 0.040\n",
      "[Epoch  30] T_loss: 0.1292, T_accuracy: 95.2982 | V_loss: 0.2230, V_accuracy: 92.1800 | Early stopping counter: 1 out of 10 | T_time: 00:12:41, T_speed: 0.039\n",
      "[Epoch  40] T_loss: 0.1006, T_accuracy: 96.3764 | V_loss: 0.2233, V_accuracy: 92.4200 | Early stopping counter: 2 out of 10 | T_time: 00:16:50, T_speed: 0.040\n",
      "[Epoch  50] T_loss: 0.0780, T_accuracy: 97.1455 | V_loss: 0.2506, V_accuracy: 92.7800 | Early stopping counter: 3 out of 10 | T_time: 00:21:00, T_speed: 0.040\n",
      "[Epoch  60] T_loss: 0.0623, T_accuracy: 97.7473 | V_loss: 0.2702, V_accuracy: 92.5200 | Early stopping counter: 4 out of 10 | T_time: 00:25:11, T_speed: 0.040\n",
      "[Epoch  70] T_loss: 0.0510, T_accuracy: 98.1309 | V_loss: 0.2948, V_accuracy: 92.5200 | Early stopping counter: 5 out of 10 | T_time: 00:29:21, T_speed: 0.040\n",
      "[Epoch  80] T_loss: 0.0447, T_accuracy: 98.3218 | V_loss: 0.3254, V_accuracy: 92.5200 | Early stopping counter: 6 out of 10 | T_time: 00:35:05, T_speed: 0.038\n",
      "[Epoch  90] T_loss: 0.0395, T_accuracy: 98.5255 | V_loss: 0.3466, V_accuracy: 92.7800 | Early stopping counter: 7 out of 10 | T_time: 00:39:17, T_speed: 0.038\n",
      "[Epoch 100] T_loss: 0.0284, T_accuracy: 98.9782 | V_loss: 0.3800, V_accuracy: 92.8800 | Early stopping counter: 8 out of 10 | T_time: 00:43:27, T_speed: 0.038\n",
      "[Epoch 110] T_loss: 0.0289, T_accuracy: 98.9455 | V_loss: 0.3874, V_accuracy: 92.5600 | Early stopping counter: 9 out of 10 | T_time: 00:47:38, T_speed: 0.038\n",
      "[Epoch 120] T_loss: 0.0302, T_accuracy: 98.8945 | V_loss: 0.3883, V_accuracy: 92.9000 | Early stopping counter: 10 out of 10 *** TRAIN EARLY STOPPED! *** | T_time: 00:51:51, T_speed: 0.039\n",
      "Final training time: 00:51:51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▃▃▄▄▅▆▆▇▇█</td></tr><tr><td>Training accuracy (%)</td><td>▁▆▇▇▇████████</td></tr><tr><td>Training loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▃▇▇▇▇███▁▂▂▃▃</td></tr><tr><td>Validation accuracy (%)</td><td>▁▇███████████</td></tr><tr><td>Validation loss</td><td>█▂▁▁▁▂▂▃▄▄▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>120</td></tr><tr><td>Training accuracy (%)</td><td>98.89455</td></tr><tr><td>Training loss</td><td>0.03018</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.03857</td></tr><tr><td>Validation accuracy (%)</td><td>92.9</td></tr><tr><td>Validation loss</td><td>0.38828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2023-11-11_15-35-33</strong> at: <a href='https://wandb.ai/gihwanjang/fashion_mnist_cnn/runs/36fzzi1n' target=\"_blank\">https://wandb.ai/gihwanjang/fashion_mnist_cnn/runs/36fzzi1n</a><br/> View job at <a href='https://wandb.ai/gihwanjang/fashion_mnist_cnn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNDA2MjE5OQ==/version_details/v5' target=\"_blank\">https://wandb.ai/gihwanjang/fashion_mnist_cnn/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNDA2MjE5OQ==/version_details/v5</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231111_153533-36fzzi1n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--wandb\", action=argparse.BooleanOptionalAction, default=True, help=\"True or False\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-b\", \"--batch_size\", type=int, default=2_048, help=\"Batch size (int, default: 2_048)\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"-e\", \"--epochs\", type=int, default=10_000, help=\"Number of training epochs (int, default:10_000)\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"-r\", \"--learning_rate\", type=float, default=1e-3, help=\"Learning rate (float, default: 1e-3)\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"-v\", \"--validation_intervals\", type=int, default=10,\n",
    "        help=\"Number of training epochs between validations (int, default: 10)\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"-p\", \"--early_stop_patience\", type=int, default=10,\n",
    "        help=\"Number of early stop patience (int, default: 10)\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8222485-660c-42f7-ba46-d3e5c3257d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
